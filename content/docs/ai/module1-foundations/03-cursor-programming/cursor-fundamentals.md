---
title: "Cursorç¼–ç¨‹æ ¸å¿ƒåŠŸèƒ½"
weight: 1
---

# Cursorç¼–ç¨‹-ä»å…¥é—¨åˆ°ç²¾é€š

## Cursorç®€ä»‹

Cursoræ˜¯ä¸€æ¬¾åŸºäºVS Codeçš„AIé©±åŠ¨ä»£ç ç¼–è¾‘å™¨ï¼Œé›†æˆäº†GPT-4ç­‰å…ˆè¿›çš„AIæ¨¡å‹ï¼Œä¸ºå¼€å‘è€…æä¾›æ™ºèƒ½ç¼–ç¨‹è¾…åŠ©ã€‚

### æ ¸å¿ƒç‰¹æ€§

```python
cursor_features = {
    "AIä»£ç ç”Ÿæˆ": "åŸºäºè‡ªç„¶è¯­è¨€æè¿°ç”Ÿæˆä»£ç ",
    "æ™ºèƒ½è¡¥å…¨": "ä¸Šä¸‹æ–‡ç›¸å…³çš„ä»£ç è¡¥å…¨",
    "ä»£ç è§£é‡Š": "ç†è§£å’Œè§£é‡Šå¤æ‚ä»£ç é€»è¾‘",  
    "é”™è¯¯è¯Šæ–­": "è‡ªåŠ¨è¯†åˆ«å’Œä¿®å¤ä»£ç é”™è¯¯",
    "é‡æ„ä¼˜åŒ–": "ä»£ç ç»“æ„ä¼˜åŒ–å’Œæ€§èƒ½æå‡",
    "æ–‡æ¡£ç”Ÿæˆ": "è‡ªåŠ¨ç”Ÿæˆä»£ç æ–‡æ¡£å’Œæ³¨é‡Š"
}
```

## Cursor Rulesè¯¦è§£

### ä»€ä¹ˆæ˜¯Cursor Rulesï¼Ÿ

Cursor Rulesæ˜¯å®šåˆ¶AIè¡Œä¸ºçš„é…ç½®æ–‡ä»¶ï¼Œè®©AIæ›´å¥½åœ°ç†è§£é¡¹ç›®ä¸Šä¸‹æ–‡å’Œç¼–ç¨‹é£æ ¼ã€‚

### åŸºç¡€Rulesé…ç½®

```javascript
// .cursorrules æ–‡ä»¶ç¤ºä¾‹
{
  "rules": {
    "language": "Python",
    "framework": "Django", 
    "style": "PEP 8",
    "testing": "pytest",
    "documentation": "Google Style"
  },
  
  "preferences": {
    "code_style": "ç®€æ´ä¼˜é›…",
    "error_handling": "è¯¦ç»†çš„å¼‚å¸¸å¤„ç†",
    "comments": "å…³é”®é€»è¾‘å¿…é¡»æœ‰æ³¨é‡Š",
    "naming": "æè¿°æ€§å˜é‡å"
  },
  
  "context": {
    "project_type": "Webåº”ç”¨",
    "team_size": "5äºº",
    "experience_level": "ä¸­çº§",
    "performance_priority": "é«˜"
  }
}
```

### é¡¹ç›®ç‰¹å®šRules

```yaml
# Reacté¡¹ç›®çš„Cursor Rules
project_type: "React Web App"
preferences:
  - ä½¿ç”¨å‡½æ•°ç»„ä»¶å’ŒHooks
  - TypeScriptä¸¥æ ¼æ¨¡å¼
  - ESLint + Prettierä»£ç è§„èŒƒ
  - ç»„ä»¶åº“ï¼šMaterial-UI
  - çŠ¶æ€ç®¡ç†ï¼šRedux Toolkit
  
coding_standards:
  - å•ä¸€èŒè´£åŸåˆ™
  - ç»„ä»¶åä½¿ç”¨PascalCase
  - æ–‡ä»¶åä½¿ç”¨camelCase
  - è¯¦ç»†çš„PropTypeså®šä¹‰
  
best_practices:
  - æ€§èƒ½ä¼˜åŒ–ï¼šä½¿ç”¨React.memo
  - é”™è¯¯è¾¹ç•Œï¼šæ¯ä¸ªé¡µé¢ç»„ä»¶
  - æµ‹è¯•ï¼šJest + React Testing Library
  - æ— éšœç¢ï¼šéµå¾ªWCAG 2.1
```

## Cursorä¸»è¦åŠŸèƒ½è¯¦è§£

### 1. AIä»£ç ç”Ÿæˆ

#### è‡ªç„¶è¯­è¨€è½¬ä»£ç 
```python
# è¾“å…¥æè¿°ï¼šåˆ›å»ºä¸€ä¸ªè®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—çš„å‡½æ•°ï¼Œæ”¯æŒç¼“å­˜
# Cursorç”Ÿæˆçš„ä»£ç ï¼š

from functools import lru_cache

@lru_cache(maxsize=128)
def fibonacci(n: int) -> int:
    """
    è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—çš„ç¬¬né¡¹ï¼ˆæ”¯æŒç¼“å­˜ä¼˜åŒ–ï¼‰
    
    Args:
        n: éè´Ÿæ•´æ•°ï¼Œè¡¨ç¤ºæ•°åˆ—çš„ä½ç½®
        
    Returns:
        ç¬¬né¡¹çš„æ–æ³¢é‚£å¥‘æ•°
        
    Raises:
        ValueError: å½“nä¸ºè´Ÿæ•°æ—¶æŠ›å‡ºå¼‚å¸¸
    """
    if n < 0:
        raise ValueError("n must be non-negative")
    
    if n <= 1:
        return n
    
    return fibonacci(n - 1) + fibonacci(n - 2)

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # è®¡ç®—å‰10é¡¹
    for i in range(10):
        print(f"F({i}) = {fibonacci(i)}")
    
    # æ€§èƒ½æµ‹è¯•
    import time
    start = time.time()
    result = fibonacci(100)
    end = time.time()
    print(f"F(100) = {result}, è®¡ç®—ç”¨æ—¶: {end - start:.4f}ç§’")
```

#### å¤æ‚é€»è¾‘å®ç°
```python
# è¾“å…¥ï¼šå®ç°ä¸€ä¸ªçº¿ç¨‹å®‰å…¨çš„å•ä¾‹æ¨¡å¼
# Cursorç”Ÿæˆï¼š

import threading
from typing import Optional, Any

class ThreadSafeSingleton:
    """
    çº¿ç¨‹å®‰å…¨çš„å•ä¾‹æ¨¡å¼å®ç°
    ä½¿ç”¨åŒé‡æ£€æŸ¥é”å®šæ¨¡å¼ç¡®ä¿çº¿ç¨‹å®‰å…¨
    """
    
    _instance: Optional['ThreadSafeSingleton'] = None
    _lock = threading.Lock()
    
    def __new__(cls, *args, **kwargs) -> 'ThreadSafeSingleton':
        # ç¬¬ä¸€æ¬¡æ£€æŸ¥ï¼ˆæ— é”ï¼‰
        if cls._instance is None:
            # è·å–é”
            with cls._lock:
                # ç¬¬äºŒæ¬¡æ£€æŸ¥ï¼ˆæœ‰é”ï¼‰
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self, data: Any = None):
        # ç¡®ä¿åªåˆå§‹åŒ–ä¸€æ¬¡
        if not hasattr(self, '_initialized'):
            self.data = data
            self._initialized = True
    
    def get_data(self) -> Any:
        """è·å–å•ä¾‹æ•°æ®"""
        return getattr(self, 'data', None)
    
    def set_data(self, data: Any) -> None:
        """è®¾ç½®å•ä¾‹æ•°æ®"""
        self.data = data

# æµ‹è¯•ä»£ç 
def test_singleton():
    """æµ‹è¯•å•ä¾‹æ¨¡å¼çš„æ­£ç¡®æ€§"""
    import concurrent.futures
    
    def create_instance(value):
        return ThreadSafeSingleton(value)
    
    # å¹¶å‘åˆ›å»ºå®ä¾‹
    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
        futures = [executor.submit(create_instance, i) for i in range(10)]
        instances = [future.result() for future in futures]
    
    # éªŒè¯æ‰€æœ‰å®ä¾‹éƒ½æ˜¯åŒä¸€ä¸ªå¯¹è±¡
    assert all(instance is instances[0] for instance in instances)
    print("âœ“ çº¿ç¨‹å®‰å…¨å•ä¾‹æµ‹è¯•é€šè¿‡")

if __name__ == "__main__":
    test_singleton()
```

### 2. æ™ºèƒ½ä»£ç è¡¥å…¨

#### ä¸Šä¸‹æ–‡æ„ŸçŸ¥è¡¥å…¨
```python
class DataProcessor:
    def __init__(self, data_source: str):
        self.data_source = data_source
        self.processed_data = []
    
    def load_data(self):
        # å½“ä½ è¾“å…¥ "def process_" æ—¶ï¼ŒCursorä¼šæ™ºèƒ½å»ºè®®ï¼š
        pass
    
    def process_data(self, transformation_func):
        """
        Cursorä¼šæ ¹æ®ç±»çš„ä¸Šä¸‹æ–‡å»ºè®®åˆé€‚çš„å®ç°ï¼š
        - æ£€æŸ¥æ•°æ®æ˜¯å¦å·²åŠ è½½
        - åº”ç”¨è½¬æ¢å‡½æ•°  
        - å­˜å‚¨å¤„ç†ç»“æœ
        - è¿”å›å¤„ç†çŠ¶æ€
        """
        if not self.processed_data:
            self.load_data()
        
        try:
            self.processed_data = [
                transformation_func(item) for item in self.raw_data
            ]
            return {"status": "success", "count": len(self.processed_data)}
        except Exception as e:
            return {"status": "error", "message": str(e)}
```

### 3. ä»£ç è§£é‡Šå’Œé‡æ„

#### ä»£ç è§£é‡ŠåŠŸèƒ½
```python
# å¤æ‚ä»£ç ç¤ºä¾‹
def complex_algorithm(data, threshold=0.5, iterations=100):
    """Cursorå¯ä»¥è§£é‡Šè¿™ä¸ªå¤æ‚ç®—æ³•çš„å·¥ä½œåŸç†"""
    
    weights = [0.1] * len(data)
    for epoch in range(iterations):
        errors = []
        for i, item in enumerate(data):
            prediction = sum(w * f for w, f in zip(weights, item['features']))
            error = item['target'] - prediction
            errors.append(abs(error))
            
            if abs(error) > threshold:
                learning_rate = 0.01 * (1 - epoch / iterations)
                for j, feature in enumerate(item['features']):
                    weights[j] += learning_rate * error * feature
        
        avg_error = sum(errors) / len(errors)
        if avg_error < threshold * 0.1:
            break
    
    return weights

# Cursorçš„è§£é‡Šï¼š
"""
è¿™æ˜¯ä¸€ä¸ªç®€åŒ–çš„æ„ŸçŸ¥å™¨å­¦ä¹ ç®—æ³•å®ç°ï¼š

1. åˆå§‹åŒ–æƒé‡ï¼šæ‰€æœ‰æƒé‡åˆå§‹åŒ–ä¸º0.1
2. è¿­ä»£è®­ç»ƒè¿‡ç¨‹ï¼š
   - å¯¹æ¯ä¸ªæ•°æ®ç‚¹è®¡ç®—é¢„æµ‹å€¼ï¼ˆç‰¹å¾åŠ æƒå’Œï¼‰
   - è®¡ç®—é¢„æµ‹è¯¯å·®ï¼ˆç›®æ ‡å€¼ - é¢„æµ‹å€¼ï¼‰
   - å¦‚æœè¯¯å·®å¤§äºé˜ˆå€¼ï¼Œæ›´æ–°æƒé‡
   - ä½¿ç”¨é€’å‡çš„å­¦ä¹ ç‡ï¼ˆéšepochå‡å°‘ï¼‰
3. æ—©åœæœºåˆ¶ï¼šå½“å¹³å‡è¯¯å·®è¶³å¤Ÿå°æ—¶æå‰ç»ˆæ­¢
4. è¿”å›è®­ç»ƒå¥½çš„æƒé‡

å…³é”®ç‰¹ç‚¹ï¼š
- è‡ªé€‚åº”å­¦ä¹ ç‡ï¼šéšè®­ç»ƒè¿›åº¦é™ä½
- åœ¨çº¿å­¦ä¹ ï¼šé€ä¸ªæ ·æœ¬æ›´æ–°æƒé‡
- æ—©åœï¼šé¿å…è¿‡æ‹Ÿåˆ
"""
```

#### ä»£ç é‡æ„å»ºè®®
```python
# åŸå§‹ä»£ç ï¼ˆå¯æ”¹è¿›ï¼‰
def calculate_stats(numbers):
    total = 0
    count = 0
    for num in numbers:
        total += num
        count += 1
    average = total / count
    
    variance_sum = 0
    for num in numbers:
        variance_sum += (num - average) ** 2
    variance = variance_sum / count
    
    return total, count, average, variance

# Cursoré‡æ„åçš„ä»£ç 
from typing import List, Tuple, NamedTuple
import statistics

class Statistics(NamedTuple):
    """ç»Ÿè®¡ç»“æœæ•°æ®ç±»"""
    total: float
    count: int
    mean: float
    variance: float
    std_deviation: float

def calculate_statistics(numbers: List[float]) -> Statistics:
    """
    è®¡ç®—æ•°å€¼åˆ—è¡¨çš„ç»Ÿè®¡ä¿¡æ¯
    
    Args:
        numbers: æ•°å€¼åˆ—è¡¨
        
    Returns:
        Statistics: åŒ…å«å„é¡¹ç»Ÿè®¡æŒ‡æ ‡çš„å‘½åå…ƒç»„
        
    Raises:
        ValueError: å½“è¾“å…¥åˆ—è¡¨ä¸ºç©ºæ—¶
    """
    if not numbers:
        raise ValueError("è¾“å…¥åˆ—è¡¨ä¸èƒ½ä¸ºç©º")
    
    total = sum(numbers)
    count = len(numbers)
    mean = statistics.mean(numbers)
    variance = statistics.variance(numbers)
    std_dev = statistics.stdev(numbers)
    
    return Statistics(
        total=total,
        count=count, 
        mean=mean,
        variance=variance,
        std_deviation=std_dev
    )

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    data = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
    stats = calculate_statistics(data)
    
    print(f"æ€»å’Œ: {stats.total}")
    print(f"æ•°é‡: {stats.count}")
    print(f"å¹³å‡å€¼: {stats.mean:.2f}")
    print(f"æ–¹å·®: {stats.variance:.2f}")
    print(f"æ ‡å‡†å·®: {stats.std_deviation:.2f}")
```

## é«˜çº§åŠŸèƒ½ä¸æŠ€å·§

### 1. é¡¹ç›®çº§åˆ«çš„AIåŠ©æ‰‹

#### é¡¹ç›®åˆ†æ
```python
# Cursorå¯ä»¥åˆ†ææ•´ä¸ªé¡¹ç›®ç»“æ„å¹¶æä¾›å»ºè®®

project_analysis = {
    "architecture_review": {
        "strengths": [
            "æ¸…æ™°çš„æ¨¡å—åˆ†ç¦»",
            "éµå¾ªMVCæ¨¡å¼",
            "è‰¯å¥½çš„ä¾èµ–æ³¨å…¥"
        ],
        "improvements": [
            "æ·»åŠ å•å…ƒæµ‹è¯•è¦†ç›–",
            "å®ç°APIæ–‡æ¡£",
            "å¢åŠ é”™è¯¯ç›‘æ§"
        ]
    },
    
    "code_quality": {
        "score": 8.5,
        "issues": [
            "éƒ¨åˆ†å‡½æ•°è¿‡é•¿ï¼Œå»ºè®®æ‹†åˆ†",
            "ç¼ºå°‘ç±»å‹æ³¨è§£",
            "å¼‚å¸¸å¤„ç†ä¸å¤Ÿå®Œå–„"
        ]
    },
    
    "security_review": {
        "vulnerabilities": [
            "SQLæ³¨å…¥é£é™©ï¼ˆusers.py:45ï¼‰",
            "æœªéªŒè¯ç”¨æˆ·è¾“å…¥ï¼ˆapi.py:67ï¼‰"
        ],
        "recommendations": [
            "ä½¿ç”¨å‚æ•°åŒ–æŸ¥è¯¢",
            "æ·»åŠ è¾“å…¥éªŒè¯ä¸­é—´ä»¶"
        ]
    }
}
```

### 2. æ™ºèƒ½è°ƒè¯•åŠ©æ‰‹

#### é”™è¯¯è¯Šæ–­
```python
# æœ‰bugçš„ä»£ç 
def process_user_data(users):
    results = []
    for user in users:
        if user.age > 18:
            processed = {
                'name': user.name.upper(),
                'email': user.email.lower(),
                'score': user.score * 1.1
            }
            results.append(processed)
    return results

# Cursorè¯Šæ–­çš„æ½œåœ¨é—®é¢˜ï¼š
"""
ğŸ” æ½œåœ¨é—®é¢˜åˆ†æï¼š

1. ç©ºå€¼å¤„ç†ç¼ºå¤±ï¼š
   - user.name å¯èƒ½ä¸ºNone -> AttributeError
   - user.email å¯èƒ½ä¸ºNone -> AttributeError
   
2. æ•°æ®ç±»å‹å‡è®¾ï¼š
   - user.age å¯èƒ½ä¸æ˜¯æ•°å­—
   - user.score å¯èƒ½ä¸ºNone
   
3. è¾¹ç•Œæƒ…å†µï¼š
   - usersåˆ—è¡¨å¯èƒ½ä¸ºç©º
   - userå¯¹è±¡å¯èƒ½ç¼ºå°‘æŸäº›å±æ€§

ğŸ› ï¸ ä¿®å¤å»ºè®®ï¼š
"""

def process_user_data_safe(users):
    """å®‰å…¨çš„ç”¨æˆ·æ•°æ®å¤„ç†å‡½æ•°"""
    if not users:
        return []
    
    results = []
    for user in users:
        try:
            # éªŒè¯å¿…è¦å±æ€§
            if not hasattr(user, 'age') or not isinstance(user.age, (int, float)):
                continue
                
            if user.age <= 18:
                continue
            
            # å®‰å…¨çš„å­—ç¬¦ä¸²å¤„ç†
            name = getattr(user, 'name', '')
            email = getattr(user, 'email', '')
            score = getattr(user, 'score', 0)
            
            if not name or not email:
                continue
            
            processed = {
                'name': str(name).upper(),
                'email': str(email).lower(),
                'score': float(score) * 1.1 if score else 0
            }
            results.append(processed)
            
        except (AttributeError, ValueError, TypeError) as e:
            # è®°å½•é”™è¯¯ä½†ç»§ç»­å¤„ç†å…¶ä»–ç”¨æˆ·
            print(f"å¤„ç†ç”¨æˆ·æ•°æ®æ—¶å‡ºé”™: {e}")
            continue
    
    return results
```

### 3. æ–‡æ¡£ç”ŸæˆåŠ©æ‰‹

```python
class APIEndpoint:
    """ç”¨æˆ·ç®¡ç†APIç«¯ç‚¹"""
    
    def __init__(self, database_connection):
        self.db = database_connection
    
    # Cursorå¯ä»¥è‡ªåŠ¨ç”Ÿæˆè¯¦ç»†çš„APIæ–‡æ¡£
    def create_user(self, user_data):
        """
        åˆ›å»ºæ–°ç”¨æˆ·
        
        Args:
            user_data (dict): ç”¨æˆ·ä¿¡æ¯
                - name (str): ç”¨æˆ·å§“åï¼Œå¿…å¡«ï¼Œ2-50å­—ç¬¦
                - email (str): é‚®ç®±åœ°å€ï¼Œå¿…å¡«ï¼Œéœ€ç¬¦åˆé‚®ç®±æ ¼å¼
                - age (int): å¹´é¾„ï¼Œå¿…å¡«ï¼Œ18-120ä¹‹é—´
                - phone (str, optional): æ‰‹æœºå·ç ï¼Œå¯é€‰
                
        Returns:
            dict: åˆ›å»ºç»“æœ
                - success (bool): æ˜¯å¦æˆåŠŸ
                - user_id (int): æ–°ç”¨æˆ·IDï¼ˆæˆåŠŸæ—¶ï¼‰
                - message (str): ç»“æœæ¶ˆæ¯
                
        Raises:
            ValueError: å½“è¾“å…¥æ•°æ®ä¸åˆæ³•æ—¶
            DatabaseError: å½“æ•°æ®åº“æ“ä½œå¤±è´¥æ—¶
            
        Example:
            >>> api = APIEndpoint(db_connection)
            >>> result = api.create_user({
            ...     'name': 'å¼ ä¸‰',
            ...     'email': 'zhangsan@example.com', 
            ...     'age': 25
            ... })
            >>> print(result)
            {'success': True, 'user_id': 123, 'message': 'ç”¨æˆ·åˆ›å»ºæˆåŠŸ'}
        """
        pass
```

## å®æˆ˜æ¡ˆä¾‹æ¼”ç¤º

### æ¡ˆä¾‹1ï¼šå¤šå¼ ExcelæŠ¥è¡¨å¤„ç†

```python
# éœ€æ±‚ï¼šå¤„ç†å¤šä¸ªExcelæ–‡ä»¶ï¼Œåˆå¹¶æ•°æ®å¹¶ç”ŸæˆæŠ¥å‘Š
# Cursorè¾…åŠ©ç”Ÿæˆçš„å®Œæ•´è§£å†³æ–¹æ¡ˆï¼š

import pandas as pd
import os
from pathlib import Path
from typing import List, Dict, Any
import logging

class ExcelReportProcessor:
    """ExcelæŠ¥è¡¨æ‰¹é‡å¤„ç†å™¨"""
    
    def __init__(self, input_dir: str, output_dir: str):
        self.input_dir = Path(input_dir)
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        # é…ç½®æ—¥å¿—
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)
    
    def find_excel_files(self) -> List[Path]:
        """æŸ¥æ‰¾æ‰€æœ‰Excelæ–‡ä»¶"""
        excel_files = []
        for ext in ['*.xlsx', '*.xls']:
            excel_files.extend(self.input_dir.glob(ext))
        
        self.logger.info(f"æ‰¾åˆ° {len(excel_files)} ä¸ªExcelæ–‡ä»¶")
        return excel_files
    
    def read_excel_file(self, file_path: Path) -> Dict[str, pd.DataFrame]:
        """è¯»å–Excelæ–‡ä»¶çš„æ‰€æœ‰å·¥ä½œè¡¨"""
        try:
            sheets = pd.read_excel(file_path, sheet_name=None)
            self.logger.info(f"æˆåŠŸè¯»å–æ–‡ä»¶: {file_path.name}")
            return sheets
        except Exception as e:
            self.logger.error(f"è¯»å–æ–‡ä»¶å¤±è´¥ {file_path.name}: {e}")
            return {}
    
    def merge_dataframes(self, all_data: List[pd.DataFrame]) -> pd.DataFrame:
        """åˆå¹¶å¤šä¸ªDataFrame"""
        if not all_data:
            return pd.DataFrame()
        
        # ç»Ÿä¸€åˆ—åï¼ˆå¤„ç†å¤§å°å†™å’Œç©ºæ ¼é—®é¢˜ï¼‰
        for df in all_data:
            df.columns = df.columns.str.strip().str.lower()
        
        # åˆå¹¶æ•°æ®
        merged_df = pd.concat(all_data, ignore_index=True)
        
        # æ•°æ®æ¸…æ´—
        merged_df = merged_df.dropna(how='all')  # åˆ é™¤å…¨ç©ºè¡Œ
        merged_df = merged_df.drop_duplicates()  # åˆ é™¤é‡å¤è¡Œ
        
        return merged_df
    
    def generate_summary_report(self, df: pd.DataFrame) -> Dict[str, Any]:
        """ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š"""
        report = {
            "basic_stats": {
                "total_rows": len(df),
                "total_columns": len(df.columns),
                "memory_usage": df.memory_usage(deep=True).sum(),
                "null_values": df.isnull().sum().sum()
            },
            "data_types": df.dtypes.value_counts().to_dict(),
            "numeric_summary": {}
        }
        
        # æ•°å€¼åˆ—ç»Ÿè®¡
        numeric_cols = df.select_dtypes(include=['number']).columns
        for col in numeric_cols:
            report["numeric_summary"][col] = {
                "mean": df[col].mean(),
                "median": df[col].median(),
                "std": df[col].std(),
                "min": df[col].min(),
                "max": df[col].max()
            }
        
        return report
    
    def process_all_files(self) -> None:
        """å¤„ç†æ‰€æœ‰Excelæ–‡ä»¶"""
        excel_files = self.find_excel_files()
        all_dataframes = []
        
        for file_path in excel_files:
            sheets = self.read_excel_file(file_path)
            
            for sheet_name, df in sheets.items():
                if not df.empty:
                    # æ·»åŠ æ•°æ®æºä¿¡æ¯
                    df['source_file'] = file_path.name
                    df['source_sheet'] = sheet_name
                    all_dataframes.append(df)
        
        # åˆå¹¶æ‰€æœ‰æ•°æ®
        merged_data = self.merge_dataframes(all_dataframes)
        
        if merged_data.empty:
            self.logger.warning("æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆæ•°æ®")
            return
        
        # ç”ŸæˆæŠ¥å‘Š
        summary_report = self.generate_summary_report(merged_data)
        
        # ä¿å­˜ç»“æœ
        self.save_results(merged_data, summary_report)
    
    def save_results(self, merged_data: pd.DataFrame, report: Dict[str, Any]) -> None:
        """ä¿å­˜å¤„ç†ç»“æœ"""
        # ä¿å­˜åˆå¹¶åçš„æ•°æ®
        output_file = self.output_dir / "merged_data.xlsx"
        with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
            merged_data.to_excel(writer, sheet_name='åˆå¹¶æ•°æ®', index=False)
            
            # åˆ›å»ºæ±‡æ€»æŠ¥å‘Šå·¥ä½œè¡¨
            report_df = pd.DataFrame([
                ["æ€»è¡Œæ•°", report["basic_stats"]["total_rows"]],
                ["æ€»åˆ—æ•°", report["basic_stats"]["total_columns"]],
                ["å†…å­˜ä½¿ç”¨", f"{report['basic_stats']['memory_usage']/1024/1024:.2f} MB"],
                ["ç©ºå€¼æ•°é‡", report["basic_stats"]["null_values"]]
            ], columns=["æŒ‡æ ‡", "å€¼"])
            
            report_df.to_excel(writer, sheet_name='æ±‡æ€»æŠ¥å‘Š', index=False)
        
        self.logger.info(f"ç»“æœå·²ä¿å­˜åˆ°: {output_file}")

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    processor = ExcelReportProcessor(
        input_dir="./excel_files",
        output_dir="./processed_reports"
    )
    processor.process_all_files()
```

### æ¡ˆä¾‹2ï¼šç–«æƒ…å®æ—¶ç›‘æ§å¤§å±

```python
# Cursorè¾…åŠ©åˆ›å»ºç–«æƒ…ç›‘æ§å¤§å±
import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
import requests

class COVID19Dashboard:
    """ç–«æƒ…å®æ—¶ç›‘æ§å¤§å±"""
    
    def __init__(self):
        st.set_page_config(
            page_title="ç–«æƒ…å®æ—¶ç›‘æ§å¤§å±",
            page_icon="ğŸ¦ ",
            layout="wide",
            initial_sidebar_state="collapsed"
        )
        
        # è‡ªå®šä¹‰CSSæ ·å¼
        self.load_custom_css()
    
    def load_custom_css(self):
        """åŠ è½½è‡ªå®šä¹‰CSSæ ·å¼"""
        st.markdown("""
        <style>
        .main-header {
            font-size: 2.5rem;
            color: #1f77b4;
            text-align: center;
            padding: 1rem 0;
            border-bottom: 2px solid #1f77b4;
            margin-bottom: 2rem;
        }
        
        .metric-card {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            padding: 1rem;
            border-radius: 10px;
            color: white;
            text-align: center;
            margin: 0.5rem 0;
        }
        
        .alert-box {
            background: #ff6b6b;
            color: white;
            padding: 1rem;
            border-radius: 5px;
            margin: 1rem 0;
        }
        </style>
        """, unsafe_allow_html=True)
    
    def fetch_covid_data(self):
        """è·å–ç–«æƒ…æ•°æ®ï¼ˆæ¨¡æ‹Ÿï¼‰"""
        # å®é™…åº”ç”¨ä¸­åº”è¯¥è°ƒç”¨çœŸå®çš„ç–«æƒ…æ•°æ®API
        import random
        
        regions = ['åŒ—äº¬', 'ä¸Šæµ·', 'å¹¿å·', 'æ·±åœ³', 'æ­å·', 'å—äº¬', 'æ­¦æ±‰', 'æˆéƒ½']
        data = []
        
        for region in regions:
            data.append({
                'region': region,
                'confirmed': random.randint(100, 10000),
                'cured': random.randint(50, 8000),
                'deaths': random.randint(0, 100),
                'risk_level': random.choice(['ä½é£é™©', 'ä¸­é£é™©', 'é«˜é£é™©']),
                'last_update': datetime.now().strftime('%Y-%m-%d %H:%M')
            })
        
        return pd.DataFrame(data)
    
    def create_overview_metrics(self, df):
        """åˆ›å»ºæ¦‚è§ˆæŒ‡æ ‡å¡ç‰‡"""
        total_confirmed = df['confirmed'].sum()
        total_cured = df['cured'].sum()
        total_deaths = df['deaths'].sum()
        cure_rate = (total_cured / total_confirmed * 100) if total_confirmed > 0 else 0
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric(
                label="ç´¯è®¡ç¡®è¯Š",
                value=f"{total_confirmed:,}",
                delta=f"+{random.randint(0, 100)}",
                delta_color="inverse"
            )
        
        with col2:
            st.metric(
                label="ç´¯è®¡æ²»æ„ˆ", 
                value=f"{total_cured:,}",
                delta=f"+{random.randint(0, 50)}",
                delta_color="normal"
            )
        
        with col3:
            st.metric(
                label="ç´¯è®¡æ­»äº¡",
                value=f"{total_deaths:,}",
                delta=f"+{random.randint(0, 5)}",
                delta_color="inverse"
            )
        
        with col4:
            st.metric(
                label="æ²»æ„ˆç‡",
                value=f"{cure_rate:.1f}%",
                delta=f"+0.{random.randint(1, 9)}%",
                delta_color="normal"
            )
    
    def create_regional_chart(self, df):
        """åˆ›å»ºåœ°åŒºåˆ†å¸ƒå›¾è¡¨"""
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("åœ°åŒºç¡®è¯Šåˆ†å¸ƒ")
            fig_bar = px.bar(
                df, 
                x='region', 
                y='confirmed',
                color='risk_level',
                color_discrete_map={
                    'ä½é£é™©': '#2ecc71',
                    'ä¸­é£é™©': '#f39c12', 
                    'é«˜é£é™©': '#e74c3c'
                },
                title="å„åœ°åŒºç¡®è¯Šç—…ä¾‹æ•°"
            )
            fig_bar.update_layout(showlegend=True)
            st.plotly_chart(fig_bar, use_container_width=True)
        
        with col2:
            st.subheader("æ²»æ„ˆç‡å¯¹æ¯”")
            df['cure_rate'] = (df['cured'] / df['confirmed'] * 100).round(1)
            
            fig_scatter = px.scatter(
                df,
                x='confirmed',
                y='cure_rate', 
                size='cured',
                color='risk_level',
                hover_data=['region'],
                title="ç¡®è¯Šæ•°é‡ vs æ²»æ„ˆç‡"
            )
            st.plotly_chart(fig_scatter, use_container_width=True)
    
    def create_trend_chart(self):
        """åˆ›å»ºè¶‹åŠ¿å›¾è¡¨"""
        st.subheader("ç–«æƒ…è¶‹åŠ¿åˆ†æ")
        
        # ç”Ÿæˆæ¨¡æ‹Ÿçš„æ—¶é—´åºåˆ—æ•°æ®
        dates = pd.date_range(
            start=datetime.now() - timedelta(days=30),
            end=datetime.now(),
            freq='D'
        )
        
        trend_data = pd.DataFrame({
            'date': dates,
            'confirmed': [random.randint(100, 500) for _ in range(len(dates))],
            'cured': [random.randint(80, 400) for _ in range(len(dates))],
            'deaths': [random.randint(0, 20) for _ in range(len(dates))]
        })
        
        # è®¡ç®—ç´¯è®¡å€¼
        trend_data['cumulative_confirmed'] = trend_data['confirmed'].cumsum()
        trend_data['cumulative_cured'] = trend_data['cured'].cumsum()
        trend_data['cumulative_deaths'] = trend_data['deaths'].cumsum()
        
        fig_trend = go.Figure()
        
        fig_trend.add_trace(go.Scatter(
            x=trend_data['date'],
            y=trend_data['cumulative_confirmed'],
            mode='lines+markers',
            name='ç´¯è®¡ç¡®è¯Š',
            line=dict(color='#e74c3c', width=3)
        ))
        
        fig_trend.add_trace(go.Scatter(
            x=trend_data['date'],
            y=trend_data['cumulative_cured'],
            mode='lines+markers', 
            name='ç´¯è®¡æ²»æ„ˆ',
            line=dict(color='#2ecc71', width=3)
        ))
        
        fig_trend.update_layout(
            title="ç–«æƒ…å‘å±•è¶‹åŠ¿",
            xaxis_title="æ—¥æœŸ",
            yaxis_title="ç´¯è®¡äººæ•°",
            hovermode='x unified'
        )
        
        st.plotly_chart(fig_trend, use_container_width=True)
    
    def create_risk_alerts(self, df):
        """åˆ›å»ºé£é™©é¢„è­¦"""
        st.subheader("ğŸš¨ é£é™©é¢„è­¦")
        
        high_risk_regions = df[df['risk_level'] == 'é«˜é£é™©']['region'].tolist()
        
        if high_risk_regions:
            st.error(f"é«˜é£é™©åœ°åŒºï¼š{', '.join(high_risk_regions)}")
        
        # æ–°å¢ç—…ä¾‹é¢„è­¦
        recent_increase = df[df['confirmed'] > 1000]['region'].tolist()
        if recent_increase:
            st.warning(f"ç—…ä¾‹æ•°è¾ƒé«˜åœ°åŒºï¼š{', '.join(recent_increase)}")
        
        # æ²»æ„ˆç‡åä½é¢„è­¦
        df['cure_rate'] = df['cured'] / df['confirmed'] * 100
        low_cure_rate = df[df['cure_rate'] < 80]['region'].tolist()
        if low_cure_rate:
            st.info(f"æ²»æ„ˆç‡æœ‰å¾…æå‡åœ°åŒºï¼š{', '.join(low_cure_rate)}")
    
    def run_dashboard(self):
        """è¿è¡Œä»ªè¡¨ç›˜"""
        st.markdown('<h1 class="main-header">ğŸ¦  ç–«æƒ…å®æ—¶ç›‘æ§å¤§å±</h1>', 
                   unsafe_allow_html=True)
        
        # è·å–æ•°æ®
        df = self.fetch_covid_data()
        
        # æ˜¾ç¤ºæœ€åæ›´æ–°æ—¶é—´
        st.sidebar.info(f"æœ€åæ›´æ–°ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        # è‡ªåŠ¨åˆ·æ–°æŒ‰é’®
        if st.sidebar.button("ğŸ”„ åˆ·æ–°æ•°æ®"):
            st.experimental_rerun()
        
        # æ¦‚è§ˆæŒ‡æ ‡
        self.create_overview_metrics(df)
        
        # åœ°åŒºåˆ†å¸ƒå›¾è¡¨
        self.create_regional_chart(df)
        
        # è¶‹åŠ¿åˆ†æ
        self.create_trend_chart()
        
        # é£é™©é¢„è­¦
        self.create_risk_alerts(df)
        
        # è¯¦ç»†æ•°æ®è¡¨
        with st.expander("ğŸ“Š è¯¦ç»†æ•°æ®"):
            st.dataframe(df, use_container_width=True)

# è¿è¡Œåº”ç”¨
if __name__ == "__main__":
    dashboard = COVID19Dashboard()
    dashboard.run_dashboard()
```

é€šè¿‡è¿™äº›å®æˆ˜æ¡ˆä¾‹ï¼Œæ‚¨å¯ä»¥çœ‹åˆ°Cursoråœ¨å¤æ‚é¡¹ç›®å¼€å‘ä¸­çš„å¼ºå¤§èƒ½åŠ›ï¼Œå®ƒä¸ä»…èƒ½ç”Ÿæˆé«˜è´¨é‡çš„ä»£ç ï¼Œè¿˜èƒ½æä¾›æ¶æ„å»ºè®®ã€é”™è¯¯è¯Šæ–­å’Œæ€§èƒ½ä¼˜åŒ–å»ºè®®ï¼Œæ˜¯ç°ä»£å¼€å‘è€…ä¸å¯æˆ–ç¼ºçš„AIç¼–ç¨‹åŠ©æ‰‹ã€‚