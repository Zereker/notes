---
title: "è¯­éŸ³åˆæˆ (TTS)"
weight: 6
---

# è¯­éŸ³åˆæˆ (TTS)

è¯­éŸ³åˆæˆ (Text-to-Speech, TTS) æ˜¯å°†æ–‡æœ¬è½¬æ¢ä¸ºè‡ªç„¶è¯­éŸ³çš„æŠ€æœ¯ã€‚æœ¬èŠ‚ä»‹ç» TTS çš„åŸºç¡€åŸç†å’Œä¸»æµæ¨¡å‹çš„ä½¿ç”¨æ–¹æ³•ã€‚

## TTS åŸºç¡€åŸç†

### ä»€ä¹ˆæ˜¯ TTSï¼Ÿ

```
æ–‡æœ¬è¾“å…¥ â†’ [TTS ç³»ç»Ÿ] â†’ è¯­éŸ³æ³¢å½¢
"Hello, world!" â†’        â†’ ğŸ”Š éŸ³é¢‘
```

TTS ç³»ç»Ÿéœ€è¦è§£å†³ï¼š
1. **æ–‡æœ¬åˆ†æ**ï¼šåˆ†è¯ã€éŸµå¾‹é¢„æµ‹ã€å‘éŸ³è½¬æ¢
2. **å£°å­¦å»ºæ¨¡**ï¼šç”Ÿæˆå£°å­¦ç‰¹å¾ï¼ˆæ¢…å°”é¢‘è°±ï¼‰
3. **å£°ç å™¨**ï¼šå°†å£°å­¦ç‰¹å¾è½¬æ¢ä¸ºæ³¢å½¢

### TTS ç³»ç»Ÿæ¶æ„

```
        ä¼ ç»Ÿ TTS æµç¨‹
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                         â”‚
â”‚  æ–‡æœ¬ â†’ [æ–‡æœ¬å‰ç«¯] â†’ éŸ³ç´ åºåˆ—            â”‚
â”‚              â†“                          â”‚
â”‚         [å£°å­¦æ¨¡å‹] â†’ æ¢…å°”é¢‘è°±            â”‚
â”‚              â†“                          â”‚
â”‚         [å£°ç å™¨] â†’ éŸ³é¢‘æ³¢å½¢              â”‚
â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ç°ä»£ç«¯åˆ°ç«¯ TTSï¼š**
- å•ä¸€æ¨¡å‹å®Œæˆå…¨éƒ¨æ­¥éª¤
- ä»£è¡¨ï¼šBark, VITS, Tacotron

### ä¸»æµ TTS æ¨¡å‹

| æ¨¡å‹ | ç±»å‹ | ç‰¹ç‚¹ |
|------|------|------|
| SpeechT5 | Seq2Seq | éœ€è¦è¯´è¯äººåµŒå…¥ |
| Bark | GPT-style | æ”¯æŒæƒ…æ„Ÿã€æ•ˆæœã€å¤šè¯­è¨€ |
| VITS | End-to-End | é«˜è´¨é‡ã€å¿«é€Ÿ |
| Tacotron 2 | Seq2Seq | ç»å…¸æ¶æ„ |
| FastSpeech 2 | Non-AR | å¹¶è¡Œç”Ÿæˆï¼Œé€Ÿåº¦å¿« |

## SpeechT5 æ¨¡å‹

### æ¨¡å‹æ¦‚è¿°

SpeechT5 æ˜¯å¾®è½¯å‘å¸ƒçš„ç»Ÿä¸€è¯­éŸ³-æ–‡æœ¬æ¨¡å‹ï¼š

```
SpeechT5 æ¶æ„
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                         â”‚
â”‚  å…±äº«ç¼–ç å™¨-è§£ç å™¨ Transformer           â”‚
â”‚                                         â”‚
â”‚  æ”¯æŒä»»åŠ¡:                               â”‚
â”‚  â€¢ TTS (æ–‡æœ¬â†’è¯­éŸ³)                       â”‚
â”‚  â€¢ ASR (è¯­éŸ³â†’æ–‡æœ¬)                       â”‚
â”‚  â€¢ è¯­éŸ³è½¬æ¢                              â”‚
â”‚  â€¢ è¯­éŸ³å¢å¼º                              â”‚
â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### åŸºç¡€ä½¿ç”¨

```python
from transformers import SpeechT5Processor, SpeechT5ForTextToSpeech, SpeechT5HifiGan
from datasets import load_dataset
import torch
import soundfile as sf

# åŠ è½½æ¨¡å‹
processor = SpeechT5Processor.from_pretrained("microsoft/speecht5_tts")
model = SpeechT5ForTextToSpeech.from_pretrained("microsoft/speecht5_tts")
vocoder = SpeechT5HifiGan.from_pretrained("microsoft/speecht5_hifigan")

# å‡†å¤‡æ–‡æœ¬
text = "Hello, this is a test of the text to speech system."
inputs = processor(text=text, return_tensors="pt")

# åŠ è½½è¯´è¯äººåµŒå…¥ï¼ˆå¿…éœ€ï¼‰
embeddings_dataset = load_dataset("Matthijs/cmu-arctic-xvectors", split="validation")
speaker_embeddings = torch.tensor(embeddings_dataset[7306]["xvector"]).unsqueeze(0)

# ç”Ÿæˆè¯­éŸ³
speech = model.generate_speech(
    inputs["input_ids"],
    speaker_embeddings,
    vocoder=vocoder
)

# ä¿å­˜éŸ³é¢‘
sf.write("output.wav", speech.numpy(), samplerate=16000)
```

### ä½¿ç”¨ Pipeline

```python
from transformers import pipeline
from datasets import load_dataset
import soundfile as sf

# åˆ›å»º TTS pipeline
synthesizer = pipeline("text-to-speech", model="microsoft/speecht5_tts")

# è·å–è¯´è¯äººåµŒå…¥
embeddings_dataset = load_dataset("Matthijs/cmu-arctic-xvectors", split="validation")
speaker_embedding = embeddings_dataset[7306]["xvector"]

# åˆæˆè¯­éŸ³
speech = synthesizer(
    "Hello, how are you today?",
    forward_params={"speaker_embeddings": speaker_embedding}
)

# ä¿å­˜
sf.write("output.wav", speech["audio"], samplerate=speech["sampling_rate"])
```

### ä¸åŒè¯´è¯äºº

```python
# CMU Arctic æ•°æ®é›†åŒ…å«å¤šä¸ªè¯´è¯äºº
# é€‰æ‹©ä¸åŒç´¢å¼•è·å–ä¸åŒå£°éŸ³

speaker_indices = {
    "male_1": 0,
    "male_2": 100,
    "female_1": 7306,
    "female_2": 7500,
}

# ä½¿ç”¨ä¸åŒè¯´è¯äºº
for name, idx in speaker_indices.items():
    speaker_emb = torch.tensor(embeddings_dataset[idx]["xvector"]).unsqueeze(0)
    speech = model.generate_speech(inputs["input_ids"], speaker_emb, vocoder=vocoder)
    sf.write(f"output_{name}.wav", speech.numpy(), samplerate=16000)
```

### SpeechT5 å±€é™æ€§

- ä»…æ”¯æŒè‹±è¯­
- éœ€è¦æä¾›è¯´è¯äººåµŒå…¥
- æŸäº›éŸ³ç´ å¯èƒ½å‘éŸ³ä¸å‡†ç¡®
- ä¸æ”¯æŒæƒ…æ„Ÿæ§åˆ¶

## Bark æ¨¡å‹

### æ¨¡å‹æ¦‚è¿°

Bark æ˜¯ Suno AI å‘å¸ƒçš„ç”Ÿæˆå¼ TTS æ¨¡å‹ï¼š

```
Bark ç‰¹ç‚¹
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                         â”‚
â”‚  â€¢ GPT-style è‡ªå›å½’ç”Ÿæˆ                  â”‚
â”‚  â€¢ æ”¯æŒ 13+ è¯­è¨€                         â”‚
â”‚  â€¢ æ”¯æŒéè¯­è¨€å£°éŸ³ï¼ˆç¬‘å£°ã€å¹æ°”ç­‰ï¼‰         â”‚
â”‚  â€¢ æ”¯æŒèƒŒæ™¯éŸ³ä¹å’Œç¯å¢ƒéŸ³                   â”‚
â”‚  â€¢ æ— éœ€è¯´è¯äººåµŒå…¥                         â”‚
â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### åŸºç¡€ä½¿ç”¨

```python
from transformers import AutoProcessor, BarkModel
import scipy

# åŠ è½½æ¨¡å‹
processor = AutoProcessor.from_pretrained("suno/bark")
model = BarkModel.from_pretrained("suno/bark")

# å‡†å¤‡æ–‡æœ¬
text = "Hello, my name is Suno. And I am an AI voice generator."
inputs = processor(text, return_tensors="pt")

# ç”Ÿæˆè¯­éŸ³
audio_array = model.generate(**inputs)
audio_array = audio_array.cpu().numpy().squeeze()

# ä¿å­˜
sample_rate = model.generation_config.sample_rate
scipy.io.wavfile.write("bark_output.wav", rate=sample_rate, data=audio_array)
```

### ä½¿ç”¨ Pipeline

```python
from transformers import pipeline
import soundfile as sf

# åˆ›å»º TTS pipeline
synthesizer = pipeline("text-to-speech", model="suno/bark-small")

# åˆæˆè¯­éŸ³ï¼ˆæ— éœ€è¯´è¯äººåµŒå…¥ï¼‰
speech = synthesizer("Hello! This is Bark speaking naturally.")

# ä¿å­˜
sf.write("bark_output.wav", speech["audio"], samplerate=speech["sampling_rate"])
```

### å¤šè¯­è¨€æ”¯æŒ

```python
# Bark æ”¯æŒå¤šè¯­è¨€
texts = {
    "en": "Hello, how are you today?",
    "zh": "ä½ å¥½ï¼Œä»Šå¤©æ€ä¹ˆæ ·ï¼Ÿ",
    "ja": "ã“ã‚“ã«ã¡ã¯ã€å…ƒæ°—ã§ã™ã‹ï¼Ÿ",
    "de": "Hallo, wie geht es dir heute?",
    "fr": "Bonjour, comment allez-vous aujourd'hui?",
}

for lang, text in texts.items():
    inputs = processor(text, return_tensors="pt")
    audio = model.generate(**inputs)
    audio_np = audio.cpu().numpy().squeeze()
    scipy.io.wavfile.write(f"bark_{lang}.wav", rate=sample_rate, data=audio_np)
```

### å£°éŸ³é¢„è®¾

```python
# ä½¿ç”¨å£°éŸ³é¢„è®¾æ§åˆ¶è¯´è¯äºº
voice_presets = [
    "v2/en_speaker_0",  # è‹±è¯­ç”·å£° 0
    "v2/en_speaker_1",  # è‹±è¯­ç”·å£° 1
    "v2/en_speaker_6",  # è‹±è¯­å¥³å£°
    "v2/zh_speaker_0",  # ä¸­æ–‡è¯´è¯äºº
]

for preset in voice_presets:
    inputs = processor(
        text,
        voice_preset=preset,
        return_tensors="pt"
    )
    audio = model.generate(**inputs)
    # ä¿å­˜...
```

### éè¯­è¨€å£°éŸ³

Bark çš„ç‹¬ç‰¹åŠŸèƒ½æ˜¯æ”¯æŒéè¯­è¨€å£°éŸ³ï¼š

```python
# æ”¯æŒçš„ç‰¹æ®Šæ ‡è®°
text_with_effects = """
[laughs] Ha ha, that's so funny!
[sighs] Well, what can I do...
[clears throat] Anyway, let me continue.
[gasps] Oh my goodness!
"""

inputs = processor(text_with_effects, return_tensors="pt")
audio = model.generate(**inputs)
```

**æ”¯æŒçš„ç‰¹æ®Šæ ‡è®°ï¼š**

| æ ‡è®° | æ•ˆæœ |
|------|------|
| `[laughs]` | ç¬‘å£° |
| `[sighs]` | å¹æ°” |
| `[clears throat]` | æ¸…å—“å­ |
| `[gasps]` | å€’å¸æ°” |
| `[music]` | èƒŒæ™¯éŸ³ä¹ |
| `â™ª` | å”±æ­Œ |
| `...` | åœé¡¿/çŠ¹è±« |

### å”±æ­Œæ¨¡å¼

```python
# Bark å¯ä»¥ç”Ÿæˆæ­Œå”±
song_text = """
â™ª Twinkle, twinkle, little star,
How I wonder what you are! â™ª
"""

inputs = processor(song_text, return_tensors="pt")
audio = model.generate(**inputs)
```

### Bark æ¨¡å‹å¤§å°

| æ¨¡å‹ | å‚æ•°é‡ | VRAM | ç‰¹ç‚¹ |
|------|--------|------|------|
| `suno/bark-small` | 300M | ~4GB | å¿«é€Ÿï¼Œè´¨é‡ä¸­ç­‰ |
| `suno/bark` | 1.5B | ~8GB | é«˜è´¨é‡ï¼Œè¾ƒæ…¢ |

### ä¼˜åŒ–æ¨ç†

```python
import torch

# ä½¿ç”¨ GPU
model = model.to("cuda")

# åŠç²¾åº¦
model = model.half()

# å¼€å¯ä¼˜åŒ–
model = model.to_bettertransformer()

# ç”Ÿæˆ
inputs = processor(text, return_tensors="pt").to("cuda")
audio = model.generate(**inputs)
```

## å…¶ä»– TTS æ¨¡å‹

### VITS (Coqui TTS)

```python
from TTS.api import TTS

# åŠ è½½ VITS æ¨¡å‹
tts = TTS("tts_models/en/ljspeech/vits")

# åˆæˆè¯­éŸ³
tts.tts_to_file(
    text="Hello world!",
    file_path="vits_output.wav"
)
```

### Edge TTS (å¾®è½¯åœ¨çº¿)

```python
import edge_tts
import asyncio

async def synthesize():
    communicate = edge_tts.Communicate(
        "Hello, this is Edge TTS speaking.",
        "en-US-JennyNeural"  # å£°éŸ³é€‰æ‹©
    )
    await communicate.save("edge_output.mp3")

asyncio.run(synthesize())
```

**Edge TTS ä¸­æ–‡å£°éŸ³ï¼š**
- `zh-CN-XiaoxiaoNeural` - æ™“æ™“ï¼ˆå¥³ï¼‰
- `zh-CN-YunxiNeural` - äº‘å¸Œï¼ˆç”·ï¼‰
- `zh-CN-YunyangNeural` - äº‘æ‰¬ï¼ˆç”·ï¼‰

## è¯­éŸ³åˆæˆå®è·µ

### å®Œæ•´ TTS ç¤ºä¾‹

```python
"""æ–‡æœ¬è½¬è¯­éŸ³å®Œæ•´ç¤ºä¾‹"""

from transformers import pipeline
import soundfile as sf
import os

class TTSEngine:
    def __init__(self, model_name="suno/bark-small"):
        """åˆå§‹åŒ– TTS å¼•æ“"""
        self.synthesizer = pipeline(
            "text-to-speech",
            model=model_name,
            device=0 if torch.cuda.is_available() else -1
        )

    def synthesize(self, text, output_path="output.wav"):
        """åˆæˆè¯­éŸ³"""
        speech = self.synthesizer(text)
        sf.write(output_path, speech["audio"], samplerate=speech["sampling_rate"])
        return output_path

    def synthesize_long_text(self, text, output_path="output.wav", max_length=200):
        """å¤„ç†é•¿æ–‡æœ¬"""
        # åˆ†å¥
        sentences = self._split_sentences(text, max_length)

        # é€å¥åˆæˆ
        audio_segments = []
        for sentence in sentences:
            speech = self.synthesizer(sentence)
            audio_segments.append(speech["audio"])

        # åˆå¹¶éŸ³é¢‘
        import numpy as np
        combined = np.concatenate(audio_segments)
        sf.write(output_path, combined, samplerate=speech["sampling_rate"])
        return output_path

    def _split_sentences(self, text, max_length):
        """åˆ†å‰²é•¿æ–‡æœ¬"""
        import re
        # æŒ‰æ ‡ç‚¹åˆ†å‰²
        sentences = re.split(r'(?<=[.!?ã€‚ï¼ï¼Ÿ])\s+', text)
        result = []
        current = ""

        for s in sentences:
            if len(current) + len(s) <= max_length:
                current += " " + s if current else s
            else:
                if current:
                    result.append(current.strip())
                current = s

        if current:
            result.append(current.strip())

        return result

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    tts = TTSEngine()

    # çŸ­æ–‡æœ¬
    tts.synthesize("Hello, how are you?", "short.wav")

    # é•¿æ–‡æœ¬
    long_text = """
    Welcome to the text to speech demonstration.
    This system can convert any text into natural sounding speech.
    It supports multiple languages and voice styles.
    """
    tts.synthesize_long_text(long_text, "long.wav")
```

### æ‰¹é‡ç”Ÿæˆ

```python
from transformers import pipeline
import soundfile as sf
from tqdm import tqdm

# åˆå§‹åŒ–
tts = pipeline("text-to-speech", model="microsoft/speecht5_tts")

# åŠ è½½è¯´è¯äººåµŒå…¥
from datasets import load_dataset
embeddings = load_dataset("Matthijs/cmu-arctic-xvectors", split="validation")
speaker_emb = embeddings[7306]["xvector"]

# æ‰¹é‡æ–‡æœ¬
texts = [
    "Welcome to our service.",
    "Please hold while we connect you.",
    "Thank you for your patience.",
    "Have a great day!",
]

# æ‰¹é‡ç”Ÿæˆ
for i, text in enumerate(tqdm(texts)):
    speech = tts(text, forward_params={"speaker_embeddings": speaker_emb})
    sf.write(f"audio_{i}.wav", speech["audio"], samplerate=speech["sampling_rate"])
```

### æµå¼åˆæˆ

```python
import torch
from transformers import BarkModel, AutoProcessor

# åŠ è½½æ¨¡å‹
model = BarkModel.from_pretrained("suno/bark-small")
processor = AutoProcessor.from_pretrained("suno/bark-small")

def stream_tts(text, chunk_size=100):
    """æµå¼æ–‡æœ¬è½¬è¯­éŸ³"""
    # åˆ†å—å¤„ç†æ–‡æœ¬
    words = text.split()
    chunks = []
    current_chunk = []

    for word in words:
        current_chunk.append(word)
        if len(" ".join(current_chunk)) >= chunk_size:
            chunks.append(" ".join(current_chunk))
            current_chunk = []

    if current_chunk:
        chunks.append(" ".join(current_chunk))

    # é€å—ç”Ÿæˆ
    for chunk in chunks:
        inputs = processor(chunk, return_tensors="pt")
        audio = model.generate(**inputs)
        yield audio.cpu().numpy().squeeze()

# ä½¿ç”¨æµå¼ç”Ÿæˆ
for audio_chunk in stream_tts("This is a long text that will be processed in chunks."):
    # å®æ—¶æ’­æ”¾æˆ–å¤„ç†
    pass
```

## è¯„ä¼° TTS è´¨é‡

### ä¸»è§‚è¯„ä¼° (MOS)

MOS (Mean Opinion Score) æ˜¯ TTS è´¨é‡çš„ä¸»è¦è¯„ä¼°æŒ‡æ ‡ï¼š

| åˆ†æ•° | è´¨é‡ |
|------|------|
| 5 | ä¼˜ç§€ |
| 4 | è‰¯å¥½ |
| 3 | ä¸€èˆ¬ |
| 2 | è¾ƒå·® |
| 1 | å¾ˆå·® |

### å®¢è§‚æŒ‡æ ‡

```python
# æ¢…å°”å€’è°±å¤±çœŸ (MCD)
def calculate_mcd(ref_mel, syn_mel):
    """è®¡ç®—æ¢…å°”å€’è°±å¤±çœŸ"""
    import numpy as np
    diff = ref_mel - syn_mel
    mcd = np.mean(np.sqrt(2 * np.sum(diff ** 2, axis=1)))
    return mcd

# F0 ç›¸å…³æ€§
def calculate_f0_correlation(ref_audio, syn_audio, sr):
    """è®¡ç®—åŸºé¢‘ç›¸å…³æ€§"""
    import librosa
    import numpy as np

    f0_ref, _, _ = librosa.pyin(ref_audio, fmin=50, fmax=500, sr=sr)
    f0_syn, _, _ = librosa.pyin(syn_audio, fmin=50, fmax=500, sr=sr)

    # è®¡ç®—ç›¸å…³ç³»æ•°
    mask = ~np.isnan(f0_ref) & ~np.isnan(f0_syn)
    corr = np.corrcoef(f0_ref[mask], f0_syn[mask])[0, 1]
    return corr
```

## å°ç»“

| æ¨¡å‹ | ä¼˜ç‚¹ | ç¼ºç‚¹ | é€‚ç”¨åœºæ™¯ |
|------|------|------|----------|
| SpeechT5 | é€Ÿåº¦å¿«ï¼Œè´¨é‡ç¨³å®š | ä»…è‹±è¯­ï¼Œéœ€è¯´è¯äººåµŒå…¥ | è‹±è¯­æœ—è¯» |
| Bark | å¤šè¯­è¨€ï¼Œæ”¯æŒæƒ…æ„Ÿ | é€Ÿåº¦æ…¢ï¼Œä¸å¤Ÿç¨³å®š | åˆ›æ„å†…å®¹ |
| VITS | é«˜è´¨é‡ï¼Œå¿«é€Ÿ | éœ€è¦é¢å¤–å®‰è£… | ç”Ÿäº§ç¯å¢ƒ |
| Edge TTS | å…è´¹åœ¨çº¿ï¼Œè´¨é‡é«˜ | éœ€è¦ç½‘ç»œ | å¿«é€ŸåŸå‹ |

**TTS ä½¿ç”¨å»ºè®®ï¼š**
1. å¿«é€ŸåŸå‹ç”¨ Edge TTS
2. ç¦»çº¿è‹±è¯­ç”¨ SpeechT5
3. å¤šè¯­è¨€æˆ–æƒ…æ„Ÿç”¨ Bark
4. ç”Ÿäº§ç¯å¢ƒè€ƒè™‘ VITS æˆ–å•†ä¸š API

---

*ä¸‹ä¸€èŠ‚ï¼š[éŸ³é¢‘åº”ç”¨](applications.md) - ç»¼åˆåº”ç”¨å®æˆ˜*
